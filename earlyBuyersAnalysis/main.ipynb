{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT:  1\n"
     ]
    }
   ],
   "source": [
    "# result: address, holdings, previousTradeTimestamp, boughtTotal, holdingCurrently\n",
    "\n",
    "import pandas as pd\n",
    "import alchemyHelper\n",
    "import graphqlHelper\n",
    "import json\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "uniswapV2Router = \"0x7a250d5630b4cf539739df2c5dacb4c659f2488d\"\n",
    "uniswapV3Router = \"0x68b3465833fb72A70ecDF485E0e4C7bD8665Fc45\"\n",
    "weiDivisible = 1000000000000000000\n",
    "\n",
    "# getting count\n",
    "with open(\"mainCOUNT.txt\", \"r\") as f:\n",
    "    rowNum = int(f.read())\n",
    "count = rowNum + 1\n",
    "\n",
    "#walletsList = pd.read_csv(\"../Common Wallet in Multiple Projects/pepe.csv\")\n",
    "#walletsList = pd.read_csv(\"../TokenAnalysis/testDEJITARUPARUGoodWallets.csv\")\n",
    "walletsList = pd.read_csv(\"ONEWALLETTEST.csv\")\n",
    "walletsList = walletsList.drop_duplicates()\n",
    "\n",
    "df = pd.DataFrame(columns=list(['Wallet_Address','Tokens_Traded', 'Positive_Trades', 'Negative_Trades', 'Still_Holding_OR_Dusted', 'Sold_Incrementally_(NotJet)', 'Transfer_To_Other_Account_OR_NULL', 'Transfer_Stablecoin', 'Average_Profit']))\n",
    "#df.to_csv('RESULTS_TEST_COWBYS.csv')\n",
    "\n",
    "for i, row in walletsList[rowNum:].iterrows():\n",
    "    tokensTraded = 0\n",
    "    stillHoldingOrDusted = 0\n",
    "    sellingIncrementally = 0\n",
    "    accountTransferORNULL = 0\n",
    "    stablecoinTransfer = 0\n",
    "    profits = {}\n",
    "\n",
    "    print(\"COUNT: \", count)\n",
    "    bigDICT = {}\n",
    "    #wallet = row[\"Address\"]\n",
    "    \n",
    "    wallet = row[\"Wallet\"]\n",
    "    #print(f\"CURRENT WALLET: {wallet}\")\n",
    "\n",
    "    positiveTrade = 0\n",
    "    negativeTrade = 0\n",
    "\n",
    "    # BUY SECTION\n",
    "    buyList = alchemyHelper.getBuys(wallet)\n",
    "    for dict in buyList:\n",
    "        txnHash = dict[\"hash\"]\n",
    "        contract = dict[\"rawContract\"][\"address\"]\n",
    "\n",
    "        if contract not in bigDICT:\n",
    "            bigDICT[contract] = {\n",
    "                \"buys\": [],\n",
    "                \"sells\": []\n",
    "            }\n",
    "\n",
    "        bigDICT[contract]['buys'].append(txnHash)\n",
    "\n",
    "    # SELL SECTION\n",
    "    sellList = alchemyHelper.getSells(wallet)\n",
    "    for dict in sellList:\n",
    "        txnHash = dict[\"hash\"]\n",
    "        contract = dict[\"rawContract\"][\"address\"]\n",
    "\n",
    "        if contract not in bigDICT:\n",
    "            bigDICT[contract] = {\n",
    "                \"buys\": [],\n",
    "                \"sells\": []\n",
    "            }\n",
    "\n",
    "        bigDICT[contract]['sells'].append(txnHash)\n",
    "\n",
    "    # bigDICT[contract]\n",
    "    # ITERATING BIG DICTIONARY\n",
    "    for contract in bigDICT:\n",
    "        # REMOVING DUPLICATES\n",
    "        bigDICT[contract][\"buys\"] = [*set(bigDICT[contract][\"buys\"])]\n",
    "        bigDICT[contract][\"sells\"] = [*set(bigDICT[contract][\"sells\"])]\n",
    "\n",
    "        # CASE0 - IRREGULARITY\n",
    "        if (bigDICT[contract][\"buys\"] == []):\n",
    "            continue\n",
    "\n",
    "        # CASE1 - still holding token or rugged/dusted\n",
    "        if (bigDICT[contract][\"sells\"] == []):\n",
    "            stillHoldingOrDusted += 1\n",
    "            continue\n",
    "\n",
    "        # CASE2 - Great buy and selling incrementally, smart trader\n",
    "        buyLen = len(bigDICT[contract][\"buys\"])\n",
    "        sellLen = len(bigDICT[contract][\"sells\"])\n",
    "        diffLen = sellLen / float(buyLen)\n",
    "        if (diffLen > 2):\n",
    "            sellingIncrementally += 1\n",
    "\n",
    "        excludeThisContract = False\n",
    "        buys = 0.0\n",
    "        # CHECKING BUYS GRAPHQL\n",
    "        for buy in bigDICT[contract][\"buys\"]:\n",
    "            result = graphqlHelper.getData(buy)\n",
    "            if (result == -1):\n",
    "                accountTransferORNULL += 1\n",
    "                excludeThisContract = True\n",
    "            elif (result == -2):\n",
    "                stablecoinTransfer += 1\n",
    "            else:\n",
    "                buys += result\n",
    "\n",
    "        sells = 0.0\n",
    "        # CHECKING SELLS GRAPHQL\n",
    "        for sell in bigDICT[contract][\"sells\"]:\n",
    "            result = graphqlHelper.getData(sell)\n",
    "            if (result == -1):\n",
    "                accountTransferORNULL += 1\n",
    "                excludeThisContract = True\n",
    "            elif (result == -2):\n",
    "                stablecoinTransfer += 1\n",
    "            else:\n",
    "                sells += result\n",
    "\n",
    "        # STABLECOIN OR JUST TRANSFER\n",
    "        if (sells - buys == 0.0 or excludeThisContract):\n",
    "            continue\n",
    "\n",
    "        # transfer maybe\n",
    "        if buys == 0: continue\n",
    "\n",
    "        profit = ((sells - buys) / buys) * 100.0\n",
    "        \n",
    "        if profit > 0: positiveTrade += 1\n",
    "        else: negativeTrade += 1\n",
    "\n",
    "        profits[contract] = profit\n",
    "        tokensTraded += 1\n",
    "\n",
    "    #CHANGE FILE NAME HERE\n",
    "    with open(\"RESULTS_TEST_DONKEY_DETAILS.json\", \"a\") as file:\n",
    "        json.dump(profits, file)    \n",
    "        \n",
    "    profitsAVG = sum(profits.values())/len(profits)\n",
    "\n",
    "    df.loc[0] = [wallet, tokensTraded, positiveTrade, negativeTrade, stillHoldingOrDusted, sellingIncrementally, accountTransferORNULL, stablecoinTransfer, profitsAVG]\n",
    "    df.to_csv('RESULTS_TEST_DONKEY.csv', mode='a', index=False, header=False)\n",
    "\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Average_Profit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\CS\\Web3Practice\\earlyBuyersAnalysis\\main.ipynb Cell 2\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CS/Web3Practice/earlyBuyersAnalysis/main.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.float_format\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CS/Web3Practice/earlyBuyersAnalysis/main.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mRESULTS_TEST_DONKEY.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CS/Web3Practice/earlyBuyersAnalysis/main.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m table\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mAverage_Profit\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\wwwbl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wwwbl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:6904\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6900\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(by):\n\u001b[0;32m   6901\u001b[0m     \u001b[39m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   6903\u001b[0m     by \u001b[39m=\u001b[39m by[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 6904\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(by, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   6906\u001b[0m     \u001b[39m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[0;32m   6907\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6908\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m   6909\u001b[0m         \u001b[39m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wwwbl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:1849\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1843\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1844\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1845\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1847\u001b[0m     )\n\u001b[0;32m   1848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1849\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1851\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1852\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Average_Profit'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "table = pd.read_csv(\"RESULTS_TEST_DONKEY.csv\")\n",
    "table.sort_values('Average_Profit', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24a65622588fb1db624ed535020f5a37a759da9d209a329d177031dbba643a35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
